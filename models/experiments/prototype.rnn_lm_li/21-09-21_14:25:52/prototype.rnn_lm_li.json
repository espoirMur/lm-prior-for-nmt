{"metrics": {"lr": [0.001], "loss": [8.704953756332397, 8.6440163230896], "ppl": [6032.722958281456, 5676.081081158782], "epoch_loss": {"TRAIN": [8.796346462397478], "VALID": [8.562081320672972]}, "epoch_ppl": {"TRAIN": [6610.049770524418], "VALID": [5229.554232699304]}}, "name": "prototype.rnn_lm_li", "finished": false, "config": {"epochs": 200, "batch_tokens": 1000, "parallel": false, "pin_memory": false, "logging": {"log_interval": 100, "checkpoint_interval": 1000, "samples_interval": 500, "emb_inspect_interval": 1000, "module_grad_interval": 500}, "optim": {"optimizer": "ranger", "lr": 0.001, "k": 10, "weight_decay": 0.0, "clip": 1, "scheduler": "plateau", "step_size": 1, "patience": 2, "eta_min": 1e-05, "min_lr": 0.0001, "gamma": 0.3, "milestones": [5, 15], "early_stop": 10}, "losses": {"lm": {"tag": "lm", "weight": 1, "perplexity": true}}, "data": {"train_path": "/Users/es.py/Projects/Personal/lm-prior-for-nmt/data/processed/mono/ln_mono_train.pp", "val_path": "/Users/es.py/Projects/Personal/lm-prior-for-nmt/data/processed/mono/ln_mono_val.pp", "subword_path": null, "seq_len": 250, "sos": true, "vocab_size": 10000, "embeddings": "../data/embeddings/lingala_embeddings_fasttext/embedding_50_all_lingala_corpus.bin"}, "model": {"mode": "LM", "type": "rnn", "emb_trainable": false, "emb_size": 50, "emb_dropout": 0.1, "emb_layer_norm": false, "emb_max_norm": null, "inp_dropout": 0.0, "rnn_size": 512, "rnn_layers": 1, "rnn_dropout": 0.1, "rnn_layer_norm": false, "rnn_type": "LSTM", "out_layer_norm": false, "tie_projections": true, "countdown": false}, "name": "prototype.rnn_lm_li", "desc": null, "config": "../configs/prototype.rnn_lm_li.yaml", "tag": null, "visdom": false, "resume_cp": null, "resume_state_id": null, "device": "cpu", "cores": 4, "src_dirs": ["/Users/es.py/Projects/Personal/lm-prior-for-nmt/models/models", "/Users/es.py/Projects/Personal/lm-prior-for-nmt/models/modules", "/Users/es.py/Projects/Personal/lm-prior-for-nmt/models/helpers"]}}